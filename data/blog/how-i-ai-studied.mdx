---
title: "Как я AI с помощью AI учил"
publishedAt: "2023-02-02"
summary: "Вы полюбому слышали про нейронки, которые там любые картинки рисуют и на любую тему подискутировать способны. Речь о Midjourney и ChatGPT. Собственно я решился научиться разрабатывать искусственный интеллект с помощью того самого любителя поговорить, с ChatGPT"
image: "/images/how-i-ai-studied/cover.png"
isPublished: true
---

<BlogHorizontalImage url="/images/how-i-ai-studied/cover.png" alt="AI robot shows examples on the blackboard how to learn AI" />

## Оглавление

1. [Знакомство](#знакомство)
2. [Выбор проекта](#выбор-проекта)
3. [Практика](#практика)

### Знакомство

Недолго думая, я подрубил VPNчик и зашёл на [сайтик OpenAI](https://openai.com/blog/chatgpt/), почитал чо как, ну и зашёл непосредственно в интерфейс для работы с самой нейронкой.
В любой IT сфере есть roadmap, пройдя который ты пройдёшь путь от нуля до профессионала. Собственно именно это я и запросил у GPT:

> Show the roadmap to learn machine learning

_"Я не знаю английского, можно не на буржуйском с GPT общаться?" - Да, с нейронкой можно на русском, но такое себе_

Нейронка посмеялась с моей тавтологии, но всё же ответила мне. Список оказался примерно таким:

1. Получи базовые навыки в программировании и выучи хотя бы 1 язык (желательно Python)
2. Научись базовой статистике и теории вероятности, так как они важны для понятия многих алгоритмов
3. Разберись в разных типах машинного обучения: обучение с учителем (supervised), без учителя (unsupervised), с подкреплением (reinforcement)
4. Разберись в базовых алгоритмах, таких как: линейная регрессия, алгоритм k-ближайших соседей, дерево решений и нейронные сети
5. Практикуйся, применяя полученные знания к реальным жизненным проблемам, используя библиотеки вроде scikit-learn и TensorFlow
6. Работай, набивай портфолио, блаблабла...

Ну первый пункт у меня благо выполнен, не зря 4 года ради одной бумажки провтухал.

Второй пунктик уже вызвал у меня немного отвращения, ибо ТВиМС (теория вероятности и мат. статистика) крайне неприятный предмет для изучения. Однако я добросовестно взял волю в кулак и прошёлся по базовому обучающему курсу, можете не переживать.

Опять же опущу моменты, связанные с математикой. Для изучения машинного обучения, как оказалось, надо бы хорошенько её знать. Тут меня флешбекнуло во времена школы и студенчества, ибо я даже линейное уравнение с двумя неизвестными решить не смог. Что тут о дифференцировании говорить.

Перейдём к интересному, к 3 пункту - что за типы машинного обучения нас ожидают. Делаю запрос:

> Give me extended explanation of supervised, unsupervised and reinforcement learning types

Буду в основном опираться на английскую терминологию, ибо на русском уши вянут от названий этих. Еще добавлю, что нейросеть отвечает мне полностью на английском. Перевожу в прямом эфире. Не удивляйтесь, если смысл покажется вам искажённым.

## Supervised (с учителем):

Supervised обучение - это такой алгоритм машинного обучения, который тренирует модель используя маркированные данные, где известен конечный и желаемый результат. Модель обучается предсказывать конечный результат, опираясь на входные данные. Модель оценивается на основе точности её предсказаний, и любые ошибки используются для регулирования параметров модели.

Примеры подобного типа обучения:
- регрессия (предсказание числового значения)
- классификация (предсказание категории)
- прогнозирование временных рядов (предсказание будущих значений, основываясь на результатах в прошлом).

## Unsupervised (без учителя):

Unsupervised обучение - это такой алгоритм машинного обучения, который тренирует модель используя немаркированные данные. Цель такого обучения - найти паттерны или структуры в данных, нежели предсказать конкретное значение. Модель не обуславливают тем, какой результат она должна выдать. Её необходимо найти паттерны и взаимосвязи самостоятельно.

Примеры подобного типа обучения:
- кластеризация (группирование данных по похожим признакам)
- снижение размерности _(dimensionality reduction)_ (уменьшение числа переменных путём получения главных переменных)
- поиск аномалий (идентификация посторонних объектов в данных).

## Reinforcement (с подкреплением):

Reinforcement обучение - это такой алгоритм машинного обучения, который тренирует модель используя систему вознаграждений. Модель получает награды или штрафы, в зависимости от её действий, и цель в данном случае - максимизировать конечную награду через неопределённое время. Такой тип обучения часто используется в системах поддержки принятия решений, где модели необходимо научиться взаимодействовать с окружающей средой и выбирать те решения, которые буду приводить к оптимальному результату.

Примеры подобного типа обучения:
- игра в видеоигры (где модель вознаграждается за победы и получает штрафы за поражение)
- контроллирование роботов (где модель учится выполнять поставленные задачи)
- торговля финансовыми активами (где модель учится как принимать инвестиционные решения, основываясь на рыночных трендах)

Отлично, мы поняли какие типы машинного обучения существуют. Перейдём к четвертому пункту, непосредственно к самим алгоритмам. Делаю поочерёдно запросы:

> explain how linear regression works

Линейная регрессия - алгоритм обучения с учителем, использующийся для предсказания непрерывных значений (таких как цены, температуры или веса) основываясь на одном или нескольких признаках (входных параметрах). Это предполагает что существует линейная зависимость между входными параметрами и целевым значением, и он ищет наиболее подходящую **линию**, представляющую данную взаимосвязь.

**Линия** представлена математически формулой `y = b0 + b1x1 + b2x2 + ... + bnxn`, где y - конечное(целевое) значение, `b0` - сдвиг по оси y, `b1, b2, ..., bn` - коэффициенты входящих параметров `x1, x2, ..., xn`. Эти коэффициенты определяют наклон линии, который представляет собой силу и направление взаимосвязи между каждым входным параметром и целевым значением.

Чтобы найти наиболее подходящую линию, алгоритм использует метод наименьших квадратов, который минимизирует сумму квадратов разностей между фактическими целевыми значениями и прогнозируемыми значениями на основе уравнения линии. Это приводит к оптимизации коэффициентов, которые можно использовать для прогнозирования новых, невидимых данных.

Линейная регрессия может применяться к данным с одним или несколькими признаками и может быть расширена до полиномиальной или множественной регрессии, где взаимосвязь между целевым значением и входными параметрами представлена ​​​​более сложным уравнением.

> explain how k-nearest neighbors work

Метод K-ближайших соседей _(K-Nearest Neighbors)_ - это unsupervised алгоритм обучения, использующийся для классификации и регрессии. Метод основан на идеи поиска ближайших точек данных (соседей) в функциональном пространстве, чтобы делать предсказания.

В данном методе, каждая точка данных представлена в виде списка признаков (входящих значений), и алгоритм ищет k-число точек данных, которые близки к новой точке данных для того, чтобы классифицировать её.

Значение переменной `k` - гиперпараметр, который пользователь может изменять, и он определяет количество соседей, которые рассматриваются для предсказания. Чем больше число `k`, тем более смягченным будет результат, в то время как наименьшее число даст более сложный и "туповатый" результат.

> explain how decision tree works

A decision tree is a tree-like model used for supervised learning in both classification and regression problems. The tree consists of internal nodes that represent decisions based on input features, and leaf nodes that represent the final prediction or output.

The algorithm starts at the root of the tree and, based on the input features, follows a path through the tree to the appropriate leaf node. The internal nodes are split based on the feature that provides the greatest information gain, which measures the reduction in entropy or impurity of the data after a split. The splits are repeated recursively on the resulting subgroups until a stopping criterion is reached, such as a maximum depth or a minimum number of samples in a leaf node.

In a classification problem, the prediction is made based on the majority class of the samples in a leaf node. In a regression problem, the prediction is made based on the mean or median of the samples in a leaf node.

Decision trees are easy to understand and interpret, and they can handle both categorical and continuous data. They can also handle non-linear relationships between the input features and the target variable, but they may be prone to overfitting and may not generalize well to new data. To avoid overfitting, techniques such as pruning (removing unnecessary splits), cross-validation, or random forests (ensembles of decision trees) can be used.

> explain how neural networks work

Neural networks are a type of machine learning algorithm inspired by the structure and function of the human brain. They are used for both supervised and unsupervised learning tasks, such as image classification, speech recognition, and natural language processing.

A neural network consists of an input layer, one or more hidden layers, and an output layer. Each layer consists of nodes (also known as neurons), which receive input from the previous layer, process the input through a non-linear activation function, and pass the output to the next layer.

In supervised learning, the input features are passed through the network, and the output of the final layer is compared to the target values. The difference between the actual and predicted values is used to update the weights and biases of the nodes in the network, so that the network can learn to make more accurate predictions. This process is repeated multiple times until the network reaches a satisfactory level of accuracy on the training data.

In unsupervised learning, the network is used to extract patterns and features from the input data without any prior knowledge of the target variables. The network can then be used for clustering, dimensionality reduction, or generative models.

Neural networks are powerful models that can handle complex and non-linear relationships between the input features and the target variable. However, they require a large amount of data for training and can be prone to overfitting if not properly designed and trained. To avoid overfitting, techniques such as regularization, early stopping, or dropout can be used.

***

### Выбор проекта

Что ж, по логике ChatGPT, мы прошли вводный курс теории, теперь готовы непосредственно к практике.

В программировании в качестве первой программы при обучении принято создавать так называемый _"Hello world"_. Данная программа просто выводил в консоль, либо на экран сообщение "Привет, мир!"

Спрошу у нейронки, какая программа является образом _"Hello world"_ в мире машинного обучения:

> What are "Hello world" starting projects in machine learning?

"Hello world" starting projects in machine learning are simple and introductory projects that are designed to help beginners get started with machine learning. They are typically small, straightforward, and focused on a specific task, such as:

1. Iris flower classification: This project involves using machine learning algorithms to classify iris flowers based on their sepal length, sepal width, petal length, and petal width. This is a classic example of a supervised classification problem.
2. Handwritten digit recognition: This project involves using machine learning algorithms to recognize handwritten digits from the MNIST dataset. This is a supervised classification problem.
3. Linear regression: This project involves using linear regression to predict a continuous value, such as the price of a house, based on one or more input features.
4. Clustering: This project involves using clustering algorithms to group similar data points together based on their features. This is an unsupervised learning problem.

These projects provide a good starting point for beginners to get a hands-on experience with machine learning, understand the basic concepts, and learn how to use different algorithms and libraries.

Окей, в этом разобрались. Для себя лично выделил линейную регрессию, так как с точки зрения математики довольно таки просто и понятно. Спросим какие именно проблемы можно решить используя данный подход:

> What kinds of projects are better for starting developing linear regression?

Kinds of projects for starting development:

- Predicting housing prices: Use linear regression to predict the prices of houses based on features such as square footage, number of bedrooms, and location.
- Sales forecasting: Use linear regression to forecast sales based on factors such as advertising spend, seasonality, and economic indicators.
- Predicting stock prices: Use linear regression to predict stock prices based on historical data and economic indicators.

These projects are simple, straightforward, and provide a good starting point for developing your skills in linear regression. They will help you understand the basics of linear regression and how to implement it in practice.

Тут меня сразу заинтересовал третий пункт - сам увлекаюсь финансами и торгую криптовалютой, поэтому почему бы не совместить полезное с приятным? Спрашиваю как именно начать разрабатывать это:

> Explain all steps for developing linear regression for predicting stock prices

Developing a linear regression model for predicting stock prices involves the following steps:

1. Data collection: Collect the historical data for the stock you want to predict prices for. This data should include the stock's opening and closing prices, volume of shares traded, and any other relevant economic indicators that may affect the stock price.
2. Data cleaning: Clean and pre-process the data to remove any missing values, outliers, and any irrelevant information. This is an important step to ensure that the data is ready for analysis.
3. Exploratory Data Analysis (EDA): Perform EDA to understand the relationships between the stock price and the other variables. This can be done by creating plots and visualizing the data.
4. Feature selection: Select the relevant variables that will be used as independent variables in the model. This is important to ensure that the model is not overfitting or underfitting the data.
5. Model selection: Choose a suitable linear regression model for the problem. Simple linear regression can be used when there is only one independent variable, while multiple linear regression is used when there are multiple independent variables.
6. Model training: Train the model using the training data. This involves estimating the parameters of the model and finding the best fit line that minimizes the sum of the squared errors between the predicted values and the actual values.
7. Model evaluation: Evaluate the model using the test data. This involves calculating various evaluation metrics, such as mean squared error (MSE), root mean squared error (RMSE), mean absolute error (MAE), and R-squared, to determine the accuracy of the model.
8. Model tuning: Fine-tune the model by adjusting the parameters and features until you get the desired level of accuracy.
9. Deployment: Deploy the model in a suitable environment, such as a web app or a mobile app, to make predictions on new data.

These steps will help you develop a linear regression model for predicting stock prices. It's important to note that stock price prediction is a challenging task and that linear regression may not always provide accurate results. However, it is a good starting point for developing your skills in machine learning.

Ну что ж. За работу!

***

### Практика

***

## Полезное чтиво для твоего мозга

[Лонгрид про машинное обучение (большинство картинок оттуда)](https://vas3k.ru/blog/machine_learning/)